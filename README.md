# Transfer-learning-for-CEUS
探讨自然场景下数据训练的模型能否较好迁移到数据量有限的超声造影视频中

本研究使用的医学数据来自中山大学第一附属医院超声科，由医生回顾性收集1999-2019年中山大学附属第一医院胆管细胞癌（intrahepatic cholangiocellular carcinoma, ICC）患者。入组标准：1、病理确诊；2、病人进行超声造影检查；3、无肝外转移、血管侵犯；4、超声造影成像前未进行过系统或局部治疗。共190例胆管细胞癌患者入组，为胆管细胞癌患者按1：1比例匹配肝细胞癌(（hepatocellular carcinoma，HCC）病例，所有胆管细胞癌和肝细胞癌病例组成本课题的研究病例，共计380人，研究采用三折的交叉验证，按肿瘤类型随机分组。入组数据为CEUS前120s的视频，使用RandiAnt转出为``.bmp''格式的图像序列，输入网络时只将需要的图片读入再合并为一个clip，从而降低数据读取时的内存和加快读取速度，所有病例由影像医生挑选和人工勾画了以下8张图片的肿瘤靶区：1、病变最大切面动脉增强早期图像；2、病变最大切面动脉增强中期图像；3、病变最大切面动脉增强峰值图像；4、增强峰值后5s图像；5、增强峰值后10s图像；6、增强峰值后20s图像；7、增强峰值后40s图像；8、CEUS120s的图像。通过对一个视频中的8个Bounding-box取最小的能够包下所有区域的Bounding-box，并将其上下左右向外扩展20个像素获取单个视频统一的截取区域，从而实现病灶区域和背景分离


本次研究使用公开发表的模型和参数，检索依据来自2020年6月1日的Paper With Code网站上计算机视觉-> 视频->视频分类任务的[排名表](https://paperswithcode.com/task/video-classification),部分公开模型虽然有着较好的性能，但因为作者认为这些网络的计算成本太高，如facebook开源的视频网络模型库[VMZ](https://github.com/facebookresearch/VMZ)中的ir-CSN-152和ir-CSN-152模型，输入32*224*224, 152层深度，没有纳入实验中。

本研究对比了2D CNN，2D CNN+BERT，C3D，I3D，SlowFast，R(2+1)D，TSM，GSM后，得到结论如下：

	1. GSM模型的性能较为优越；
	2. 2D CNN可以比部分时空网络效果好；
	3. BERT结构相对2D CNN，性能更好，且BERT resnet50 和BERT bninception性能较突出；
	4. Slow通道的迁移效果最差，不适合应用在CEUS中；
	5.TSM网络的迁移性能较差，这可能因为Shift模块的模式在CEUS上无法迁移利用；
	6. I3D的表现较为平庸；
	7. C3D对在更多数据时，性能提升明显，实现了0.9的正确率和0.867的ICC敏感性，在所有实验中变现最好的；
	8. R(2+1)D resnet34相比resnet34+BERT，性能提升更明显,基于resnet 50比resnet 34性能好，我们推断如果使用更深的resnet网络，性能会提升更高，因而是最有潜力的模型；
	9. 提高网络的视频采样的图像数目能够普遍地提升分类性能；
	10. 虽然原模型的训练基于密集采样，但均匀采样的迁移效果更好，因为数据包含了完整的造影剂增强和消退过程；
	11. 数据清洗虽然去除了21\%的图像，但平衡了HCC和ICC的数据量，直接使用原始数据时，有3/4的模型对ICC的敏感性变差，但在C3D上性能和敏感度都得到了提升，所以建议在具体使用对处理过和未处理数据集都测试；
	12. non-local结构虽然可以提升原问题的分类能力，但全局特征的关联不适合迁移到CEUS中；
	13. 在训练过程中，2D CNN的时间和计算消耗最少，训练是，1000次迭代在5分钟左右；2D+BERT稍微慢一点，但比GSM和TSM快；R(2+1)D的计算量较大；运行较慢；C3D，SlowFast, Slow基于3D卷积，计算量最大，运行时间最长，1000次迭代需要20分钟左右。
	14. 对不同网络对所有病例分类结果可视化可以发现，个别病例在绝大部分网络中都无法正确识别，这种局限可能来自数据集，也可能是迁移学习无法获得区分力强的特征。


本研究是第一个系统研究视频模型在医学三维数据集中迁移能力的报告。
